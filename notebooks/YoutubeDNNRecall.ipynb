{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0091c9bc",
   "metadata": {},
   "source": [
    "# YoutubeDNN 召回实现\n",
    "\n",
    "## 1. 下载文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c313ac3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "filename = 'ml-100k.zip'\n",
    "if not os.path.exists(filename):\n",
    "    # 下载文件\n",
    "    urlretrieve(\"http://files.grouplens.org/datasets/movielens/ml-100k.zip\", filename)\n",
    "    zip_ref = zipfile.ZipFile(filename, 'r')\n",
    "    zip_ref.extractall()\n",
    "    print(f'Download File: {filename}')\n",
    "print(f'{filename} existed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabbf09d",
   "metadata": {},
   "source": [
    "## 2. Preprocess\n",
    "\n",
    "处理四种数据：movies, users, ratings, genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7500c678",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# user --- u.user\n",
    "users_col = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('ml-100k/u.user', sep='|', names=users_col)\n",
    "\n",
    "# rating --- u.data\n",
    "ratings_col = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv('ml-100k/u.data', sep='\\t', names=ratings_col)\n",
    "\n",
    "# movies and genres --- aggregate u.item and u.genre\n",
    "movies_col = ['movie_id', 'movie_title', 'release_date', 'video_release_date', 'IMDb_URL']\n",
    "genres_col = ['genre_unknown', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', \n",
    "              'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "movies_col = movies_col + genres_col\n",
    "movies = pd.read_csv('ml-100k/u.item', sep='|', names=movies_col)\n",
    "\n",
    "print(users.dtypes, '\\n')\n",
    "print(ratings.dtypes, '\\n')\n",
    "print(movies.dtypes, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a362733d",
   "metadata": {},
   "source": [
    "将电影所属的 genre 拼接成一个多值属性，比如 `3,4,5,15` 的形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d84870",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "genre_encoded = {x:i for i, x in enumerate(genres_col)}\n",
    "all_genre = [','.join([str(i) for i,x in enumerate(arr) if x == 1]) for arr in movies[genres_col].values]\n",
    "movies['all_genres'] = all_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b1b454",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "movies.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f67a20c",
   "metadata": {},
   "source": [
    "将 ratings, movies, users 全部聚合在一起"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d2ca8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratings_all = ratings.merge(movies, on='movie_id').merge(users, on='user_id')\n",
    "ratings_all = ratings_all.drop(columns=genres_col)\n",
    "ratings_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafe703b",
   "metadata": {},
   "source": [
    "根据 ratings 的数值来判断喜欢还是不喜欢，>= 3 则为喜欢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c606898",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# TODO 这里可以换为 0 和 1\n",
    "ratings_all['like_type'] = np.where(ratings_all['rating']>=3, 'like', 'dislike')\n",
    "ratings_all['movie_name'] = ratings_all['movie_title'].str[:-6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4df6f8",
   "metadata": {},
   "source": [
    "按照 user_id 来排序，内部再根据时间戳来排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4f57a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratings_all=ratings_all.sort_values(by=['user_id', 'timestamp'])\n",
    "ratings_all.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85412007",
   "metadata": {},
   "source": [
    "将可能会不连续的 user_id 映射转化为连续的 user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cad971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = ratings_all['user_id'].unique().tolist()\n",
    "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
    "\n",
    "movie_ids = ratings_all[\"movie_id\"].unique().tolist()\n",
    "movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\n",
    "\n",
    "title_ids = ratings_all[\"movie_name\"].unique().tolist()\n",
    "title2title_encoded = {x: i for i, x in enumerate(title_ids)}\n",
    "\n",
    "\n",
    "occupation_ids = ratings_all['occupation'].unique().tolist()\n",
    "oc2oc_encoded = {x: i for i, x in enumerate(occupation_ids)}\n",
    "\n",
    "ratings_all['user'] = ratings_all['user_id'].map(user2user_encoded)\n",
    "ratings_all['movie'] = ratings_all['movie_id'].map(movie2movie_encoded)\n",
    "ratings_all['title_d'] = ratings_all['movie_name'].map(title2title_encoded)\n",
    "ratings_all['occupation'] = ratings_all['occupation'].map(oc2oc_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7158b4df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratings_all.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab45625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用户看过所有电影并且根据喜欢和不喜欢进行分类\n",
    "movie_list = ratings_all.groupby(['user','like_type'])['movie'].apply(list).reset_index()\n",
    "# 每个用户看过的所有电影\n",
    "title_list = ratings_all.groupby(['user'])['title_d'].apply(list).reset_index()\n",
    "# 每个用户看过电影的所有题材类型\n",
    "genre_list = ratings_all.groupby(['user'])['all_genres'].unique().apply(list).reset_index()\n",
    "genre_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0e6c66",
   "metadata": {},
   "source": [
    "去除重复的 genres 项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7212ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_list['all_genres'] = genre_list['all_genres'].apply(lambda x: [i for i in list(set(','.join(x))) if i.isdigit()] )\n",
    "genre_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981aed3d",
   "metadata": {},
   "source": [
    "将电影分为用户喜欢和不喜欢的两种类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35824330",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_video_list = movie_list.pivot(index='user', columns='like_type', values='movie').reset_index()\n",
    "# 填充无效值，可能会存在没有喜欢的或者没有不喜欢的\n",
    "user_video_list.fillna(ratings_all['movie'].max()+1, inplace=True)\n",
    "user_video_list.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa751433",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = ratings_all[['user', 'occupation', 'gender', 'age']]\n",
    "# 相当于复制一份数据？\n",
    "user_data =user_data.drop_duplicates()\n",
    "user_data = user_data.reset_index()\n",
    "user_data = user_data.drop('index',axis=1)\n",
    "user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a8ac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = user_video_list.merge(title_list, on='user').merge(genre_list).merge(user_data)\n",
    "dataset['like'] = dataset['like'].apply(lambda x: x if type(x) is list else [x])\n",
    "dataset['dislike'] = dataset['dislike'].apply(lambda x: x if type(x) is list else [x])\n",
    "dataset['predict_labels'] = dataset['like'].apply(lambda x: x[-1])\n",
    "dataset['like'] = dataset['like'].apply(lambda x: x[:-1])\n",
    "dataset['age'] = (dataset['age'] - dataset['age'].min()) / (dataset['age'].max() - dataset['age'].min())\n",
    "dataset['gender'] = np.where(dataset['gender'] == 'M', 0, 1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923193ff",
   "metadata": {},
   "source": [
    "预处理完毕，开始分割数据集为训练集和测试集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d75007",
   "metadata": {},
   "source": [
    "## 3. 构建模型\n",
    "\n",
    "首先引入依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09842e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Layer, Embedding, Dense, Input, BatchNormalization\n",
    "from keras.models import Model\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60716a8",
   "metadata": {},
   "source": [
    "Masked Embedding Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339783f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedEmbeddingsAggregatorLayer(Layer):\n",
    "    def __init__(self, agg_mode='sum', *args, **kwargs):\n",
    "        super(MaskedEmbeddingsAggregatorLayer, self).__init__(**kwargs)\n",
    "        \n",
    "        if agg_mode not in ['sum', 'mean']:\n",
    "            raise NotImplementedError\n",
    "        self.agg_mode = agg_mode\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, inputs, mask=None):\n",
    "        # 对不规则张量进行 mask 操作\n",
    "        masked_embeddings = tf.ragged.boolean_mask(inputs, mask)\n",
    "        if self.agg_mode == 'sum':\n",
    "            aggregated = tf.reduce_sum(masked_embeddings, axis=1)\n",
    "        elif self.agg_mode == 'mean':\n",
    "            aggregated = tf.reduce_mean(masked_embeddings, axis=1)\n",
    "        return aggregated\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {'agg_mode': self.agg_mode}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de924bdf",
   "metadata": {},
   "source": [
    "L2 Normalize Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c52e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2NormLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(L2NormLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            inputs = tf.ragged.boolean_mask(inputs, mask).to_tensor()\n",
    "        return tf.math.l2_normalize(inputs, axis=-1)\n",
    "    \n",
    "    def compute_mask(self, inputs, mask):\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3147fb10",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7eb94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoutubeDNNRecall(Model):\n",
    "    def __init__(self, feature_columns, feature_vocab, ebd_dim, **kwargs):\n",
    "        super(YoutubeDNNRecall, self).__init__(**kwargs)\n",
    "        self.feature_columns = feature_columns\n",
    "        # 注意设置 mask_zero 为 true\n",
    "        self.feature_ebd = Embedding(input_dim=feature_vocab, input_length=1, output_dim=ebd_dim, embeddings_initializer='random_normal', mask_zero=True, name='feature_embeddings')\n",
    "        self.label_ebd = Embedding(input_dim=feature_vocab, input_length=1, output_dim=ebd_dim, embeddings_initializer='random_normal', mask_zero=True, name='label_embeddings')\n",
    "        self.mask_ebd = MaskedEmbeddingsAggregatorLayer('mean', name='aggregate_embedding')\n",
    "        self.dense1 = Dense(units=64, activation='relu', name='dense_1')\n",
    "        self.dense2 = Dense(units=64, activation='relu', name='dense_2')\n",
    "        self.dense3 = Dense(units=64, activation='relu', name='dense_3')\n",
    "        self.bn = BatchNormalization()\n",
    "        self.l2 = L2NormLayer(name='l2_norm')\n",
    "        self.final = Dense(feature_vocab, activation=tf.nn.softmax, name='dense_output')\n",
    "        \n",
    "    def summary(self, line_length=None, positions=None, print_fn=None, expand_nested=False, show_trainable=False):\n",
    "#         inputs = {f['name']: Input(shape=(), dtype=tf.string if f['dtype'] == str else f['dtype'], name=f['name']) for f in self.feature_columns}\n",
    "        inputs = [Input(shape=(None,)) for i in range(4)]\n",
    "        model = Model(inputs, outputs=self.call(inputs))\n",
    "        keras.utils.plot_model(model, 'model.png', show_shapes=True)\n",
    "        model.summary()\n",
    "        \n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        # TODO 对于不同的数据集需要对名称进行处理\n",
    "#         feature_ebd = self.mask_ebd(self.l2(self.feature_ebd(inputs['title_d'])))\n",
    "#         liked_ebd = self.mask_ebd(self.l2(self.feature_ebd(inputs['like'])))\n",
    "#         disliked_ebd = self.mask_ebd(self.l2(self.feature_ebd(inputs['dislike'])))\n",
    "#         genre_ebd = self.mask_ebd(self.l2(self.feature_ebd(inputs['all_genres'])))\n",
    "        feature_ebd = self.mask_ebd(self.l2(self.feature_ebd(inputs[0])))\n",
    "        liked_ebd = self.mask_ebd(self.l2(self.label_ebd(inputs[1])))\n",
    "        disliked_ebd = self.mask_ebd(self.l2(self.label_ebd(inputs[2])))\n",
    "        genre_ebd = self.mask_ebd(self.l2(self.label_ebd(inputs[3])))\n",
    "        x = tf.concat([feature_ebd, liked_ebd, disliked_ebd, genre_ebd], axis=1)\n",
    "#         x = self.bn(self.dense1(x))\n",
    "        x = self.dense1(x)\n",
    "#         x = self.bn(self.dense2(x))\n",
    "        x = self.dense2(x)\n",
    "        x = self.bn(self.dense3(x))\n",
    "        return self.final(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dbb8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    "    {'name': 'title_d', 'dtype': object},\n",
    "    {'name': 'like', 'dtype': object},\n",
    "    {'name': 'dislike', 'dtype': object},\n",
    "    {'name': 'all_genres', 'dtype': object}\n",
    "]\n",
    "model = YoutubeDNNRecall(feature_columns, ratings_all['movie'].max()+2, 16)\n",
    "model.summary()\n",
    "optimizer = keras.optimizers.get('adam')\n",
    "loss = 'sparse_categorical_crossentropy'\n",
    "model.compile(loss=loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a5a1e4",
   "metadata": {},
   "source": [
    "## 4. 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c02992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset[dataset.user <= 600]\n",
    "test_data = dataset[dataset.user>600]\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6ca6cc",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences as ps\n",
    "\n",
    "x = [ps(train_data['title_d']), ps(train_data['like']), ps(train_data['dislike']), ps(train_data['all_genres'])]\n",
    "y = train_data['predict_labels'].values\n",
    "\n",
    "model.fit(x, y, epochs=500)\n",
    "test_x = [ps(test_data['title_d']), ps(test_data['like']), ps(test_data['dislike']), ps(test_data['all_genres'])]\n",
    "preds = model.predict(test_x)\n",
    "test_data['predicted_label'] = np.array([np.argmax(a) for a in preds])\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bbd355",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.argsort(preds,direction='DESCENDING',axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ee29d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.top_k(preds, k=20, sorted=True, name=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

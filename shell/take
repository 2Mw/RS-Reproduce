#!/data/amax/b510/yl/.conda/envs/rs/bin/python
import math
import os
import tensorflow as tf
import time
import sys
from pynvml.smi import nvidia_smi as smi

'Use to take a position of GPU'

SIZE = 50000
MEMORY_LIMIT = 8192  # MiB


def get_available_gpu(ins, num=1):
    """
    Return the available numbers of gpus,

    :param ins: The instance of smi
    :param num: The number of gpu you want to select.
    :return: "0", "0,1", "0,2,3"
    """
    g = ''
    res = ins.DeviceQuery('memory.free')
    for idx, i in enumerate(res['gpu']):
        if i['fb_memory_usage']['free'] > MEMORY_LIMIT:
            g += f'{idx},'
            if len(g) / 2 == num:
                break
    return g[0:-1]


if __name__ == '__main__':
    ins = smi.getInstance()
    count = ins.DeviceQuery('count')['count']
    if len(sys.argv) > 1:
        SELECTED_GPU = sys.argv[1]
    else:
        SELECTED_GPU = get_available_gpu(ins)
        if len(SELECTED_GPU) == 0:
            SELECTED_GPU = f'{count - 1}'

    while True:
        res = ins.DeviceQuery('memory.free')
        gpu = res['gpu'][int(SELECTED_GPU)]
        free_ = gpu['fb_memory_usage']['free']
        print(f'\rCurrently gpu({SELECTED_GPU}) free memory {free_}.  -{time.ctime()}', end="")
        if free_ >= MEMORY_LIMIT:
            SIZE = min(int(math.sqrt(free_ / 2 * 1e6 / 8) * 0.5), SIZE)
            print(f'\nsuitable size if {SIZE}')
            break
        time.sleep(1)

    os.environ["CUDA_VISIBLE_DEVICES"] = SELECTED_GPU
    gpus = tf.config.experimental.list_physical_devices("GPU")
    for gpu in gpus:
        tf.config.experimental.set_memory_growth(gpu, False)
    cfg = tf.compat.v1.ConfigProto()
    cfg.gpu_options.per_process_gpu_memory_fraction = 1.0
    a = tf.ones([1, 1], dtype=tf.int32, name='123')
    fails = 0

    while True:
        s = time.time()
        try:
            a = tf.random.uniform([SIZE, SIZE], name='123')
        except:
            if fails % 100 == 0:
                print('Failed')
            fails += 1
        finally:
            print(f'cost time: {time.time() - s:.2f}s')
            if a.shape[0] == SIZE:
                break
            time.sleep(0.5)

    print('Allocate Over')
    while True:
        a = tf.math.softmax(tf.math.log(a))
        # time.sleep(10)
